<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><!-- InstanceBegin template="/Templates/vcmainL0.dwt" codeOutsideHTMLIsLocked="false" -->

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<!-- InstanceBeginEditable name="doctitle" -->
<title>Oscars Lab | UTokyo</title>
<!-- InstanceEndEditable -->
<META name="subject" content="UTokyo Optical Sensing and Camera System Lab. led by Yinqiang Zheng (鄭 銀強)" /> 
<META name="description" content="UTokyo Optical Sensing and Camera System Lab. led by Yinqiang Zheng (鄭 銀強)" />
<META name="keywords" content="Computer Vision, Camera System, 3D Imaging, Color, Computer Science" /> 
<META name="viewport" content="width=device-width, initial-scale=1.0">
<!-- InstanceBeginEditable name="head" -->
<!-- InstanceEndEditable -->

<link rel="stylesheet" href="./src/main.css" media="all" type="text/css" /> 

<link rel="icon" href="images/icon_64.ico" />
<link rel="SHORTCUT ICON" href="images/icon_64.ico" />

<!-- InstanceParam name="Optional_Title" type="boolean" value="true" -->
<!-- InstanceParam name="path" type="boolean" value="true" -->
<!-- InstanceParam name="page_title" type="boolean" value="true" -->

</head>

<body>
<div class="topmenubar">
  <div class="topmenu">
<!-- MENU BAR AND TITLE -->

<table width="100%" border="0" cellspacing="0" cellpadding="0" style="text-decoration:none; font-size:0px;" >
  <td width="360px" valign="top" border="0" cellspacing="0" cellpadding="0"><a href="index.html"><img src="images/logo.svg" width="340" height="56" alt="OscarsLab" /></a></td>
  <td>
  <table width="100%"  border="0" cellpadding="0" cellspacing="0" style="text-decoration:none; font-size:0px;" >
  <tr>
  <td style="font-family: Arial;" width="155" height="26px">
  <P>&nbsp;</P></td>
  </tr>
  <tr>
  <td style="font-family: Arial;">
  <a href="researchareas.html" style="text-decoration:none;font-size:13px;color:#666666;">
    RESEARCH AREAS
  </a><a style="text-decoration:none;font-size:13px;padding-right: 25px;">&nbsp;</a>
  <a href="people.html" style="text-decoration:none;font-size:13px;color:#666666;">
    TEAM
  </a><a style="text-decoration:none;font-size:13px;padding-right: 25px;">&nbsp;</a>
  <a href="publications.html" style="text-decoration:none;font-size:13px;color:#666666;">
    PUBLICATIONS
  </a><a style="text-decoration:none;font-size:13px;padding-right: 25px;">&nbsp;</a>
  <a href="openings.html" style="text-decoration:none;font-size:13px;color:#666666;">
    OPENINGS
  </a><a style="text-decoration:none;font-size:13px;padding-right: 25px;">&nbsp;</a>
  <a href="aboutus.html" style="text-decoration:none;font-size:13px;color:#666666;">
    ABOUT US
  </a>                    
  </td>
  </tr>
  </table>
</td>
</table>
</div>
</div>

<div class="container">
  <div class="content">

<!-- PATH BAR -->
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#F4F4F4" style="text-decoration:none; font-size:0px;" >
<tr>
<td  width="360" height = "30" style="font-family: Arial;">
<a href="index.html" style="text-decoration:none; font-size:13px; color:#666666; margin:0; padding-left: 7px; padding-right: 0px;" align="left"> HOME </a>
<!-- InstanceBeginEditable name="path" --> 
<a href="researchareas.html" style="text-decoration:none; font-size:13px; color:#666666; margin:0; padding-left: 0px; padding-right: 0px;" align="left">> Research Areas </a>
<!-- InstanceEndEditable -->
</td>
<td width="600" style="font-family: Arial;">
<!-- InstanceBeginEditable name="indicator" -->
<p style="display:block;padding-left: 0px;">
<img src="images/barlong.png" height="7" alt="indicator" align="left"/>
</p>
<!-- InstanceEndEditable -->
</td>
</tr>
</table>

<!-- GREY BORDER -->
<table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#F4F4F4">
    
<tr>       <!-- MAIN BODY SNACK -->
<td align="center" style="font-family: Arial;">
<table width="960" border="0" cellspacing="16" cellpadding="0" bgcolor="#FFFFFF" style="border: solid 1px #DDD;-moz-border-radius:5px; -webkit-border-radius:5px; border-radius:5px; text-align: left;">
<tr>
<td colspan="2">
              <table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#FFFFFF">
<tr>
<td><!-- InstanceBeginEditable name="page_title" -->
  <p style="text-decoration:none; font-size:18px; font-weight:bold; color:#666666; padding-left: 0px;">Research Areas: Computer Graphics &amp; Vision</p>
<!-- InstanceEndEditable -->
  <table width="100%" border="0" cellspacing="0" cellpadding="0" bgcolor="#FFFFFF">
<tr>
<td style="font-family: Arial;"><!-- InstanceBeginEditable name="Main text" -->
 
  <table width="100%"  border="0">
    <tr>
      <td width="26%" height="139"><img src="wordle_publicationlist/wordcloud.svg" alt="publication list wordle" width="353" height="237" border="0" /></td>
      <td width="1%" rowspan="2">&nbsp;</td>
      <td width="73%" rowspan="2"><p style="font-size:14px; color:#333; margin:0; padding:0;">
        Visual computing defines technologies and applications that <strong>integrate computer graphics with computer vision</strong>. 
        Computer graphics describes foundations and applications of acquisition, representation, and interaction with the three-dimensional (3D) real and the virtual world, 
        while computer vision allows for a deeper understanding of the real world in a form of two-dimensional (2D) images or video. 
        The Optical Sensing and Camera System (Oscars) Lab at UTokyo is particularly interested in visual phenomena related with <strong>light transport</strong> from a light source 
        to the visual perception in our brain via light traversal over 3D surfaces. The abstracts of our research include the fundamental elements of the real world: 
        light, color, geometry, simulation, and even interaction among these elements. 
        In particular, we are focusing on <strong>acquiring material appearance</strong> for better color representation in 3D graphics, <strong>hyperspectral 3D imaging</strong> 
        for a deeper physical understanding of light transport, and <strong>color perception in 3D</strong> for deeper understanding color. 
        Our contributions in this research allow for <strong>various hardware designs and software applications of visual computing</strong>. </p>
        <p align="right" style="font-size:14px; color:#333; margin:0; padding:0;"> 
        -- Dr. Yinqiang Zheng</p></td>
    </tr>
    <tr>
      <td valign="top" align="center"><p style="font-size:11px; color:rgb(141, 140, 140); margin:0; padding:0;">Titles of all our publications are visualized by <a href="http://www.wordclouds.com/" target="_new">wordclouds</a> in Dec 2020.</p></td>
      </tr>
    <tr>
      <td height="2" colspan="5" class="small"></td>
    </tr>
  </table>
 <table width="100%"  border="0">
   <tr>
     <td align="center"><img src="images/grad_line.gif" width="840" height="1"></td>
   </tr>
 </table>
  <table width="100%"  border="0">
    <tr>
      <td colspan="3"><p style="font-size:18px; color:#666; margin:0; padding:0;"><strong><br />
        High-Performance Advanced Imaging:</strong></p></td>
    </tr>
    <tr>
      <td><a href="siggraph2012/index.html"><img src="images/tbd.png" alt="hdr characterization" width="237" height="158" border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>3D Imaging Spectroscopy</strong></p>
        <p style="font-size:14px; color:#333; margin:0; padding:0;">We introduce an end-to-end measurement system for capturing spectral data on 3D objects. We developed a compressive sensing imager to make it suitable for acquiring such data in a hyperspectral range at high spectral and spatial resolution.  We fully characterize the imaging system, and document its accuracy. This imager is integrated into a 3D scanning system to enable the measurement of the diffuse spectral reflectance and fluorescence.</p></td>
    </tr>
    <tr>
      <td><a href="minhkimphd2010/index.html"><img src="images/tbd.png" alt="hdr characterization" width="237" height="158" border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>High-Dynamic-Range Color Reproduction</strong></p>
        <p style="font-size:14px; color:#333; margin:0; padding:0;">Classical color reproduction systems fail to reproduce HDR images due to the dynamic range of luminance present in HDR images.  Motivated by the idea to bridge the gap between cross-media color reproduction and HDR imaging, this project investigates the fundamentals and the infrastructure of cross-media color reproduction and restructures them with respect to HDR imaging, and develops a novel reproduction system for HDR imaging. </p></td>
    </tr>
    <tr>
      <td><a href="eg2008/index.html" border="0"><img src="images/tbd.png" alt="hdr characterization" width="237" height="158" border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>High-Dynamic-Range Imaging</a></strong></p>
        <p style="font-size:14px; color:#333; margin:0; padding:0;">Digital imaging has become a standard  practice but are optimized for plausible visual reproduction of a physical  scene. However, visual  reproduction is just one application of digital images. We propose a novel characterization technique for HDR imaging, allowing us to build a physically-meaningful HDR radiance map to measure real-world radiance. The achieved accuracy of this technique rivals that of a spectroradiometer.</p></td>
    </tr>
    </table>
<table width="100%"  border="0">
  <tr>
        <td width="15%" valign="top">
        <p style="font-size:18px; color:#999; margin:0; margin-bottom:10px; padding:0;"><strong>Publications:</strong></td>
        <td width="81%"><ul>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
                <!-- paper here -->
            </p>
          </li>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
              <!-- paper here -->
              </p>
            </li>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
            <!-- paper here --> 
            </p>
          </li>
        </ul></td>
        <td width="4%" rowspan="2"><p>&nbsp;</p></td>
      </tr>
  <tr>
    <td width="15%" valign="top">&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  </table>
  
    
 <table width="100%"  border="0">
   <tr>
     <td align="center"><img src="images/grad_line.gif" width="840" height="1"></td>
   </tr>
 </table>
  <table width="100%"  border="0">
    <tr>
      <td colspan="3"><p style="font-size:18px; color:#666; margin:0; padding:0;"><strong><br />Machine Learning-based Graphics and Vision:</strong></p></td>
    </tr>    
    <tr>
      <td><a href="publications.html"><img src="images/tbd.png" alt="xlrcam" width="237" height="158" border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>Deep Learning-based Advanced Spectral Imaging</strong></p>
        <p style="font-size:14px; color:#333; margin:0; padding:0;"> We developed a novel hyperspectral imaging system that can provide very high accuracy in reconstructing spectral information from compressive input. We built a spatio-spectral compressive imager, which incorporates without our spectral reconstruction algorithm that can provide high spatial and spectral resolution, overcoming the long-last tradeoff of compressive hyperspectral imaging.</p></td>
    </tr>
    <tr>
      <td><a href="publications.html" border="0"><img src="images/tbd.png" alt="insitu" width="237" height="158"  border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>Joint Learning-Based High-Dynamic-Range Imaging</strong></p>
        <p style="font-size:14px; color:#333; margin:0; padding:0;">We propose an interlaced HDR imaging via joint learning. It jointly solves two traditional problems of deinterlacing and denoising that arise in interlaced video imaging with different exposures. We first solve the deinterlacing problem using joint dictionary learning via sparse coding. Since partial information of detail in differently exposed rows is often available via interlacing, we make use of the information to reconstruct details of the extend dynamic range from the interlaced video input. Second, we jointly solve the denoising problem by tailoring sparse coding to better handle additive noise in low-/high-exposure rows.</p></td>
    </tr>
      </table>
      <table width="100%"  border="0">
  <tr>
        <td width="15%" valign="top">
        <p style="font-size:18px; color:#999; margin:0; margin-bottom:10px; padding:0;"><strong>Publications:</strong></td>
        <td width="81%"><ul>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
            <!-- paper here --> 
            </p>
          </li>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
            <!-- paper here --> 
            </p>
          </li>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
            <!-- paper here --> 
            </p>
          </li>
        </ul></td>
        <td width="4%" rowspan="2"><p>&nbsp;</p></td>
      </tr>
  <tr>
    <td width="15%" valign="top">&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  </table>
  
 <table width="100%"  border="0">
   <tr>
     <td align="center"><img src="images/grad_line.gif" width="840" height="1"></td>
   </tr>
 </table>
  <table width="100%"  border="0">
    <tr>
      <td colspan="3"><p style="font-size:18px; color:#666; margin:0; padding:0;"><strong><br />Color Visual Perception:</strong></p></td>
    </tr>    
    <tr>
      <td><a href="siggraph2009/index.html"><img src="images/tbd.png" alt="xlrcam" width="237" height="158" border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>High-Dynamic-Range Color Appearance Model</strong></p>
        <p style="font-size:14px; color:#333; margin:0; padding:0;"> We developed a novel color appearance model that not only predicts human visual perception but is also directly applicable to HDR imaging. We built a  customized display device, which produces high luminances in order to conduct color experiments. The scientific measurements of human color perception from these experiments enables me to derive a color appearance model which can cover the full range of the human visual system.</p></td>
    </tr>
    <tr>
      <td><a href="siggraph2011/index.html" border="0"><img src="images/tbd.png" alt="insitu" width="237" height="158"  border="0"/></a></td>
      <td>&nbsp;</td>
      <td><p style="font-size:18px; color:#333; margin:0; margin-bottom:10px; padding:0;"><strong>Spatially-Varying Appearance Model</strong></p>
       <p style="font-size:14px; color:#333; margin:0; padding:0;">Color perception is recognized to vary with surrounding spatial structure, but the impact of edge smoothness on color has not been studied in color appearance modeling. We study the appearance of color under different degrees of edge smoothness.  Based on our experimental data, we have developed a computational model that predicts this appearance change. The model can be integrated into existing color appearance models. </p></td>
    </tr>
      </table>
      <table width="100%"  border="0">
  <tr>
        <td width="15%" valign="top">
        <p style="font-size:18px; color:#999; margin:0; margin-bottom:10px; padding:0;"><strong>Publications:</strong></td>
        <td width="81%"><ul>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
            <!-- paper here --> 
            </p>
          </li>
          <li>
            <p style="font-size:14px; color:#333; margin:0; padding:0;">
            <!-- paper here --> 
            </p>
          </li>
        </ul></td>
        <td width="4%" rowspan="2"><p>&nbsp;</p></td>
      </tr>
  <tr>
    <td width="15%" valign="top">&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  </table>
  

<!-- InstanceEndEditable --></td>
</tr>
</table>
</td>
</tr> 
</table>
</td>
</tr>


<tr>  
  <td style="font-family: Arial;" valign="bottom" width="85%">
    <p style="font-size:12px; color:#BBBBBB; margin:0; padding:0;"> © Optical Sensing and Camera System Laboratory (Oscars Lab), 
      The University of Tokyo.
    All rights reserved.</p>
    </td>

<td align="right" valign="bottom" width="15%">  <!-- logo block --><a href="https://www.u-tokyo.ac.jp/"><img src="images/todai_logo.png" width="160" alt="TODAI" /></a></td>
<!-- end logo block -->
</tr>
</table>
</td>
</tr>
  <tr>
    <td>&nbsp;</td>
  </tr>
</table>   
<!-- end gray boarder --> 
<!-- end .content --></div>
<!-- end .container --></div>
</body>
<!-- InstanceEnd -->
</html>
